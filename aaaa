
Exercício_1_Tokenização
Exercício_1_Tokenização_
[ ]
!pip  install nltk==3.5
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting nltk==3.5
  Downloading nltk-3.5.zip (1.4 MB)
     |████████████████████████████████| 1.4 MB 7.0 MB/s 
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (1.1.0)
Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (2022.6.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5) (4.64.0)
Building wheels for collected packages: nltk
  Building wheel for nltk (setup.py) ... done
  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434690 sha256=1fa1f929cf2c7d08f8646c6d733540d0be3514e9590f7110a5729b705e71e4f1
  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266
Successfully built nltk
Installing collected packages: nltk
  Attempting uninstall: nltk
    Found existing installation: nltk 3.7
    Uninstalling nltk-3.7:
      Successfully uninstalled nltk-3.7
Successfully installed nltk-3.5
[10]
0s
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('machado')
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
[nltk_data] Downloading package machado to /root/nltk_data...
True
[11]
0s
from nltk.corpus import machado
machado.fileids()
['contos/macn001.txt',
 'contos/macn002.txt',
 'contos/macn003.txt',
 'contos/macn004.txt',
 'contos/macn005.txt',
 'contos/macn006.txt',
 'contos/macn007.txt',
 'contos/macn008.txt',
 'contos/macn009.txt',
 'contos/macn010.txt',
 'contos/macn011.txt',
 'contos/macn012.txt',
 'contos/macn013.txt',
 'contos/macn014.txt',
 'contos/macn015.txt',
 'contos/macn016.txt',
 'contos/macn017.txt',
 'contos/macn018.txt',
 'contos/macn019.txt',
 'contos/macn020.txt',
 'contos/macn021.txt',
 'contos/macn022.txt',
 'contos/macn023.txt',
 'contos/macn024.txt',
 'contos/macn025.txt',
 'contos/macn026.txt',
 'contos/macn027.txt',
 'contos/macn028.txt',
 'contos/macn029.txt',
 'contos/macn030.txt',
 'contos/macn031.txt',
 'contos/macn032.txt',
 'contos/macn033.txt',
 'contos/macn034.txt',
 'contos/macn035.txt',
 'contos/macn036.txt',
 'contos/macn037.txt',
 'contos/macn038.txt',
 'contos/macn039.txt',
 'contos/macn040.txt',
 'contos/macn041.txt',
 'contos/macn042.txt',
 'contos/macn043.txt',
 'contos/macn044.txt',
 'contos/macn045.txt',
 'contos/macn046.txt',
 'contos/macn047.txt',
 'contos/macn048.txt',
 'contos/macn049.txt',
 'contos/macn050.txt',
 'contos/macn051.txt',
 'contos/macn052.txt',
 'contos/macn053.txt',
 'contos/macn054.txt',
 'contos/macn055.txt',
 'contos/macn056.txt',
 'contos/macn057.txt',
 'contos/macn058.txt',
 'contos/macn059.txt',
 'contos/macn060.txt',
 'contos/macn061.txt',
 'contos/macn062.txt',
 'contos/macn063.txt',
 'contos/macn064.txt',
 'contos/macn065.txt',
 'contos/macn066.txt',
 'contos/macn067.txt',
 'contos/macn068.txt',
 'contos/macn069.txt',
 'contos/macn070.txt',
 'contos/macn071.txt',
 'contos/macn072.txt',
 'contos/macn073.txt',
 'contos/macn074.txt',
 'contos/macn075.txt',
 'contos/macn076.txt',
 'contos/macn077.txt',
 'contos/macn078.txt',
 'contos/macn079.txt',
 'contos/macn080.txt',
 'contos/macn081.txt',
 'contos/macn082.txt',
 'contos/macn083.txt',
 'contos/macn084.txt',
 'contos/macn085.txt',
 'contos/macn086.txt',
 'contos/macn087.txt',
 'contos/macn088.txt',
 'contos/macn089.txt',
 'contos/macn090.txt',
 'contos/macn091.txt',
 'contos/macn092.txt',
 'contos/macn093.txt',
 'contos/macn094.txt',
 'contos/macn095.txt',
 'contos/macn096.txt',
 'contos/macn097.txt',
 'contos/macn098.txt',
 'contos/macn099.txt',
 'contos/macn100.txt',
 'contos/macn101.txt',
 'contos/macn102.txt',
 'contos/macn103.txt',
 'contos/macn104.txt',
 'contos/macn105.txt',
 'contos/macn106.txt',
 'contos/macn107.txt',
 'contos/macn108.txt',
 'contos/macn109.txt',
 'contos/macn110.txt',
 'contos/macn111.txt',
 'contos/macn112.txt',
 'contos/macn113.txt',
 'contos/macn114.txt',
 'contos/macn115.txt',
 'contos/macn116.txt',
 'contos/macn117.txt',
 'contos/macn118.txt',
 'contos/macn119.txt',
 'contos/macn120.txt',
 'contos/macn121.txt',
 'contos/macn122.txt',
 'contos/macn123.txt',
 'contos/macn124.txt',
 'contos/macn125.txt',
 'contos/macn126.txt',
 'contos/macn127.txt',
 'contos/macn128.txt',
 'contos/macn129.txt',
 'contos/macn130.txt',
 'contos/macn131.txt',
 'contos/macn132.txt',
 'contos/macn133.txt',
 'contos/macn134.txt',
 'contos/macn135.txt',
 'contos/macn136.txt',
 'contos/macn137.txt',
 'critica/mact01.txt',
 'critica/mact02.txt',
 'critica/mact03.txt',
 'critica/mact04.txt',
 'critica/mact05.txt',
 'critica/mact06.txt',
 'critica/mact07.txt',
 'critica/mact08.txt',
 'critica/mact09.txt',
 'critica/mact10.txt',
 'critica/mact11.txt',
 'critica/mact12.txt',
 'critica/mact13.txt',
 'critica/mact14.txt',
 'critica/mact15.txt',
 'critica/mact16.txt',
 'critica/mact17.txt',
 'critica/mact18.txt',
 'critica/mact19.txt',
 'critica/mact20.txt',
 'critica/mact21.txt',
 'critica/mact22.txt',
 'critica/mact23.txt',
 'critica/mact24.txt',
 'critica/mact25.txt',
 'critica/mact26.txt',
 'critica/mact27.txt',
 'critica/mact28.txt',
 'critica/mact29.txt',
 'critica/mact30.txt',
 'critica/mact31.txt',
 'critica/mact32.txt',
 'critica/mact33.txt',
 'critica/mact34.txt',
 'critica/mact35.txt',
 'critica/mact36.txt',
 'critica/mact37.txt',
 'critica/mact38.txt',
 'critica/mact39.txt',
 'critica/mact40.txt',
 'critica/mact41.txt',
 'critica/mact42.txt',
 'critica/mact43.txt',
 'critica/mact44.txt',
 'critica/mact45.txt',
 'cronica/macr01.txt',
 'cronica/macr02.txt',
 'cronica/macr03.txt',
 'cronica/macr04.txt',
 'cronica/macr05.txt',
 'cronica/macr06.txt',
 'cronica/macr07.txt',
 'cronica/macr08.txt',
 'cronica/macr09.txt',
 'cronica/macr10.txt',
 'cronica/macr11.txt',
 'cronica/macr12.txt',
 'cronica/macr13.txt',
 'cronica/macr14.txt',
 'cronica/macr15.txt',
 'cronica/macr16.txt',
 'cronica/macr17.txt',
 'cronica/macr18.txt',
 'cronica/macr19.txt',
 'cronica/macr20.txt',
 'cronica/macr21.txt',
 'cronica/macr22.txt',
 'cronica/macr23.txt',
 'cronica/macr24.txt',
 'miscelanea/mams01.txt',
 'miscelanea/mams02.txt',
 'miscelanea/mams03.txt',
 'miscelanea/mams04.txt',
 'miscelanea/mams05.txt',
 'miscelanea/mams06.txt',
 'miscelanea/mams07.txt',
 'miscelanea/mams08.txt',
 'miscelanea/mams09.txt',
 'miscelanea/mams10.txt',
 'poesia/maps01.txt',
 'poesia/maps02.txt',
 'poesia/maps03.txt',
 'poesia/maps04.txt',
 'poesia/maps05.txt',
 'poesia/maps06.txt',
 'poesia/maps07.txt',
 'romance/marm01.txt',
 'romance/marm02.txt',
 'romance/marm03.txt',
 'romance/marm04.txt',
 'romance/marm05.txt',
 'romance/marm06.txt',
 'romance/marm07.txt',
 'romance/marm08.txt',
 'romance/marm09.txt',
 'romance/marm10.txt',
 'teatro/matt01.txt',
 'teatro/matt02.txt',
 'teatro/matt03.txt',
 'teatro/matt04.txt',
 'teatro/matt05.txt',
 'teatro/matt06.txt',
 'teatro/matt07.txt',
 'teatro/matt08.txt',
 'teatro/matt09.txt',
 'teatro/matt10.txt',
 'traducao/matr01.txt',
 'traducao/matr02.txt',
 'traducao/matr03.txt']
[12]
0s
texto = machado.raw('romance/marm05.txt')
texto = texto[10082:10954].replace('\n','')
texto

[13]
0s
from nltk.tokenize import sent_tokenize
sentencas = sent_tokenize(texto, language='portuguese')
for i, sent in enumerate(sentencas):
  print(i,'-',sent)
0 - Como este apelido de Cubas lhecheirasse excessivamente a tanoaria, alegava meu pai, bisneto de Damião, que odito apelido fora dado a um cavaleiro, herói nas jornadas da África, em prêmioda façanha que praticou, arrebatando trezentas cubas aos mouros.
1 - Meu pai erahomem de imaginação; escapou à tanoaria nas asas de um calembour.
2 - Era umbom caráter, meu pai, varão digno e leal como poucos.
3 - Tinha, é verdade, unsfumos de pacholice; mas quem não é um pouco pachola nesse mundo?
4 - Releva notarque ele não recorreu à inventiva senão depois de experimentar a falsificação;primeiramente, entroncou-se na família daquele meu famoso homônimo, ocapitão-mor, Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592,e por esse motivo é que me deu o nome de Brás.
5 - Opôs-se-lhe, porém, a família docapitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.
[14]
0s
from nltk.tokenize import word_tokenize
palavras = word_tokenize(texto, language='portuguese')
print(palavras)
['Como', 'este', 'apelido', 'de', 'Cubas', 'lhecheirasse', 'excessivamente', 'a', 'tanoaria', ',', 'alegava', 'meu', 'pai', ',', 'bisneto', 'de', 'Damião', ',', 'que', 'odito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', ',', 'herói', 'nas', 'jornadas', 'da', 'África', ',', 'em', 'prêmioda', 'façanha', 'que', 'praticou', ',', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros', '.', 'Meu', 'pai', 'erahomem', 'de', 'imaginação', ';', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour', '.', 'Era', 'umbom', 'caráter', ',', 'meu', 'pai', ',', 'varão', 'digno', 'e', 'leal', 'como', 'poucos', '.', 'Tinha', ',', 'é', 'verdade', ',', 'unsfumos', 'de', 'pacholice', ';', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo', '?', 'Releva', 'notarque', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', ';', 'primeiramente', ',', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', ',', 'ocapitão-mor', ',', 'Brás', 'Cubas', ',', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', ',', 'onde', 'morreu', 'em', '1592', ',', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás', '.', 'Opôs-se-lhe', ',', 'porém', ',', 'a', 'família', 'docapitão-mor', ',', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas', '.']
[15]
0s
from nltk.tokenize import sent_tokenize, word_tokenize
sentecas = sent_tokenize(texto, language='portuguese')
for i, sent in enumerate(sentencas):
   print(i,'-',word_tokenize(sent, language='portuguese')) 
0 - ['Como', 'este', 'apelido', 'de', 'Cubas', 'lhecheirasse', 'excessivamente', 'a', 'tanoaria', ',', 'alegava', 'meu', 'pai', ',', 'bisneto', 'de', 'Damião', ',', 'que', 'odito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', ',', 'herói', 'nas', 'jornadas', 'da', 'África', ',', 'em', 'prêmioda', 'façanha', 'que', 'praticou', ',', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros', '.']
1 - ['Meu', 'pai', 'erahomem', 'de', 'imaginação', ';', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour', '.']
2 - ['Era', 'umbom', 'caráter', ',', 'meu', 'pai', ',', 'varão', 'digno', 'e', 'leal', 'como', 'poucos', '.']
3 - ['Tinha', ',', 'é', 'verdade', ',', 'unsfumos', 'de', 'pacholice', ';', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo', '?']
4 - ['Releva', 'notarque', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', ';', 'primeiramente', ',', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', ',', 'ocapitão-mor', ',', 'Brás', 'Cubas', ',', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', ',', 'onde', 'morreu', 'em', '1592', ',', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás', '.']
5 - ['Opôs-se-lhe', ',', 'porém', ',', 'a', 'família', 'docapitão-mor', ',', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas', '.']
[16]
0s
# import string library function
import string
punctuations = list(string.punctuation)
print(punctuations)
['!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\', ']', '^', '_', '`', '{', '|', '}', '~']
[17]
0s
from nltk.tokenize import sent_tokenize,word_tokenize
sentencas = sent_tokenize(texto,language='portuguese')
for i,sent in enumerate(sentencas):
  sent_sem_pontuacao = [i for i in word_tokenize(sent,language='portuguese') if i not in punctuations]
  print(i,'-',sent_sem_pontuacao)
0 - ['Como', 'este', 'apelido', 'de', 'Cubas', 'lhecheirasse', 'excessivamente', 'a', 'tanoaria', 'alegava', 'meu', 'pai', 'bisneto', 'de', 'Damião', 'que', 'odito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', 'herói', 'nas', 'jornadas', 'da', 'África', 'em', 'prêmioda', 'façanha', 'que', 'praticou', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros']
1 - ['Meu', 'pai', 'erahomem', 'de', 'imaginação', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour']
2 - ['Era', 'umbom', 'caráter', 'meu', 'pai', 'varão', 'digno', 'e', 'leal', 'como', 'poucos']
3 - ['Tinha', 'é', 'verdade', 'unsfumos', 'de', 'pacholice', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo']
4 - ['Releva', 'notarque', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', 'primeiramente', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', 'ocapitão-mor', 'Brás', 'Cubas', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', 'onde', 'morreu', 'em', '1592', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás']
5 - ['Opôs-se-lhe', 'porém', 'a', 'família', 'docapitão-mor', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas']
[18]
0s
stopwords = nltk.corpus.stopwords.words('portuguese')
print(stopwords)
['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']
[19]
0s
from nltk.tokenize import sent_tokenize, word_tokenize
sentencas = sent_tokenize(texto, language='portuguese')
for i,sent in enumerate(sentencas):
  sent_sem_pontuacao = [i for i in word_tokenize(sent, language='portuguese')if i not in punctuations]
  sent_sem_stopwords = [i for i in sent_sem_pontuacao if i not in stopwords]
  print(i,'-',sent_sem_stopwords)
0 - ['Como', 'apelido', 'Cubas', 'lhecheirasse', 'excessivamente', 'tanoaria', 'alegava', 'pai', 'bisneto', 'Damião', 'odito', 'apelido', 'dado', 'cavaleiro', 'herói', 'jornadas', 'África', 'prêmioda', 'façanha', 'praticou', 'arrebatando', 'trezentas', 'cubas', 'mouros']
1 - ['Meu', 'pai', 'erahomem', 'imaginação', 'escapou', 'tanoaria', 'asas', 'calembour']
2 - ['Era', 'umbom', 'caráter', 'pai', 'varão', 'digno', 'leal', 'poucos']
3 - ['Tinha', 'verdade', 'unsfumos', 'pacholice', 'pouco', 'pachola', 'nesse', 'mundo']
4 - ['Releva', 'notarque', 'recorreu', 'inventiva', 'senão', 'experimentar', 'falsificação', 'primeiramente', 'entroncou-se', 'família', 'daquele', 'famoso', 'homônimo', 'ocapitão-mor', 'Brás', 'Cubas', 'fundou', 'vila', 'São', 'Vicente', 'onde', 'morreu', '1592', 'motivo', 'deu', 'nome', 'Brás']
5 - ['Opôs-se-lhe', 'porém', 'família', 'docapitão-mor', 'então', 'imaginou', 'trezentas', 'cubas', 'mouriscas']
[20]
0s
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,1))
bow = cv.fit_transform(sentencas)
print('BoW Shape:',bow.shape)
print('BoW Vocabulário (',len(cv.vocabulary_),'palavras ):',cv.vocabulary_)
print('Primeira sentença:',bow[0].toarray())
print('Segunda sentença:',bow[1].toarray())
BoW Shape: (6, 81)
BoW Vocabulário ( 81 palavras ): {'este': 26, 'apelido': 3, 'lhecheirasse': 43, 'excessivamente': 27, 'alegava': 1, 'bisneto': 7, 'damião': 14, 'odito': 56, 'fora': 33, 'dado': 13, 'cavaleiro': 11, 'herói': 35, 'jornadas': 40, 'da': 12, 'áfrica': 80, 'prêmioda': 67, 'façanha': 31, 'praticou': 65, 'arrebatando': 4, 'aos': 2, 'mouros': 49, 'erahomem': 23, 'imaginação': 37, 'escapou': 24, 'asas': 6, 'calembour': 9, 'era': 22, 'umbom': 74, 'caráter': 10, 'varão': 76, 'digno': 18, 'leal': 41, 'poucos': 64, 'tinha': 73, 'verdade': 77, 'unsfumos': 75, 'pacholice': 60, 'mas': 44, 'quem': 68, 'pouco': 63, 'pachola': 59, 'nesse': 52, 'mundo': 50, 'releva': 70, 'notarque': 54, 'recorreu': 69, 'inventiva': 39, 'senão': 71, 'depois': 16, 'experimentar': 28, 'falsificação': 29, 'primeiramente': 66, 'entroncou': 20, 'na': 51, 'daquele': 15, 'famoso': 30, 'homônimo': 36, 'ocapitão': 55, 'brás': 8, 'fundou': 34, 'vila': 79, 'são': 72, 'vicente': 78, 'onde': 57, 'morreu': 46, '1592': 0, 'por': 61, 'esse': 25, 'motivo': 47, 'me': 45, 'deu': 17, 'nome': 53, 'opôs': 58, 'lhe': 42, 'porém': 62, 'docapitão': 19, 'foi': 32, 'então': 21, 'imaginou': 38, 'as': 5, 'mouriscas': 48}
Primeira sentença: [[0 1 1 2 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1
  0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0
  0 0 0 0 0 0 0 0 1]]
Segunda sentença: [[0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0]]

check
0s
completed at 8:40 PM
*values: object, hint
To undo cell deletion use Ctrl+M Z or the Undo option in the Edit menu
